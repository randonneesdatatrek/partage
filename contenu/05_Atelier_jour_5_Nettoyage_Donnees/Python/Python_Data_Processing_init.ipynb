{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('bioinfo_3.8': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52454c618a4204657519cbab42273bb942d0a30f08c27de48ae386072d003f99"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data.Trek 2021 - Week 2 : Data Prepocessing and Cleaning in Python\n",
    "## Your journey in data prepocessing and cleaning with pandas\n",
    "\n",
    "Author: Savandara Ladyson Besse, UdeM - Département de Biochimie et médecine moléculaire\n",
    "\n",
    "![text here](./images/pandas.jpg)\n",
    "\n",
    "## Useful readings about pandas\n",
    "- <a href='https://pandas.pydata.org/docs/user_guide/10min.html#min'>10 min tutorial on pandas</a>\n",
    "- <a href='https://pandas.pydata.org/docs/user_guide/index.html#user-guide'>All the secrets about pandas</a>\n",
    "\n",
    "## Credits\n",
    "- Inspiration for the plan of this tutorial from <a href='https://towardsdatascience.com/data-wrangling-with-pandas-5b0be151df4e'>Towards data science</a>\n",
    "- Dataset 1: Breast cancer data from <a href='https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)'>UCI</a>\n",
    "- Dataset 2: Generated dataset based on the graduated bioinformatics alumni list from the biochemistry department of UdeM\n",
    "\n",
    "## Today's tutorial\n",
    "1. Data exploration\n",
    "2. Accessing, slicing and selecting data\n",
    "3. Dealing with missing values\n",
    "4. Dealing with duplicated values\n",
    "5. Customizing your dataframe (filter by columns or rows)\n",
    "6. Your time to play\n",
    "<br><br>\n",
    "\n",
    "_______ \n",
    "\n",
    "<br>\n",
    "\n",
    "### Situation 1: \n",
    "### You have been hired as data scientist at the Montreal Cancer Treatment Institute. Your new lab told you that they have a really insteresting dataset of breast cancer data and they want you to check if the table can be used without any changes.\n",
    "### How will you do?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "source": [
    "### I. Data exploration\n",
    "\n",
    "### __Determinant choice__: What do you want to do, first?\n",
    "- [ ]  Upload the data in my notebook now! - 1\n",
    "- [ ]  Take a look on the data, first! - 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data_path = 'https://raw.githubusercontent.com/ladyson1806/AEBINUM/master/datatrek_2021/data/breast_cancer_data.csv' #### change with aebinum when done"
   ]
  },
  {
   "source": [
    "#### If you choose the choice 1, then compute this cell\n",
    "breast_dataset = pd.read_csv(breast_data_path)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Let's check the file then..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you choose the choice 2, then compute this cell\n",
    "breast_dataset = pd.read_csv(breast_data_path, comment='#')"
   ]
  },
  {
   "source": [
    "- Other possible solution:<br>\n",
    "`breast_dataset = pd.read_csv('./data/breast_cancer_data.csv', skiprows=21)`\n",
    "\n",
    "<h4 align='center'> By the way, what does mean CSV?</h4>\n",
    "\n",
    "- Let's take a look to our table now! It loads into a python object called dataframe.\n",
    "\n",
    "> NB: If you are curious about how create a dataframe from scratch, take a look <a href='https://www.geeksforgeeks.org/python-pandas-dataframe/'>here</a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset"
   ]
  },
  {
   "source": [
    "NB: You could visualize all the dataset table on you jupyter notebook using the following lines: \n",
    "```\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "```\n",
    "But it will make your jupyter notebook pretty slow (displaying the whole dataset will consume your raw memory)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### General questions about the dataset\n",
    "\n",
    "### 1. How many rows and columns do we have?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = breast_dataset.shape\n",
    "print(f'This dataset has {rows} rows and {columns} columns')"
   ]
  },
  {
   "source": [
    "### 2. What are the type of the values in each column?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " breast_dataset.dtypes"
   ]
  },
  {
   "source": [
    "### 3. How can we check the number of each unique value per column?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset.nunique()"
   ]
  },
  {
   "source": [
    "### 4. Do you want to see some statistics? Are all the columns there? Why?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "breast_dataset.describe()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#### You can customize the shown percentiles\n",
    "breast_dataset.describe(percentiles=[0.1,0.5, 0.9])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### 5. How can we count the number of values for categorical data?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### How many patients have each doctor?\n",
    "breast_dataset.groupby(by=['doctor_name']).size()   # This aggreates the data by the column name\n",
    "                                                    # and pass the aggregation function (size = count)"
   ]
  },
  {
   "source": [
    "> More about the groupby function: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### EXERCISE:\n",
    "### Answer to the following questions, and provide the line that helped you to give the answer:\n",
    "\n",
    "1. How many unique patients do we have in this study?\n",
    "1. What type of values contain the column marginal_adhesion?\n",
    "1. What is the minimum size that can describe the cell uniformity?\n",
    "1. What is the maximal number of counted mitoses? <br>\n",
    "1. How many patients with a severe type of breast cancer has each doctor? (hint, use the groupby function) <br> print the \n",
    "\n",
    "### EXTRA QUESTIONS\n",
    "\n",
    "6. Create the dataframe containing the answer of the question 5\n",
    "    - Hint: Put the counts in a column called 'count'\n",
    "7. Use this dataframe to plot a barplot graph with the `seaborn` package \n",
    "    - Hint: `seaborn.barplot()` documentation: https://seaborn.pydata.org/generated/seaborn.barplot.html#seaborn.barplot\n",
    "8. Put your code for question 1 & 2 in two different functions\n",
    "    - How to write a function: https://swcarpentry.github.io/python-novice-gapminder/16-writing-functions/\n",
    "9. Write a function that answers to question 1 & 2 at the same time\n",
    "\n",
    "\n",
    "_______ "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 6.\n",
    "######\n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 7.\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 8\n",
    "def get_table(breast_dataset, col1, col2):\n",
    "    ###### \n",
    "    return table\n",
    "\n",
    "def display_barplot(table, title, width, height):\n",
    "    '''\n",
    "    \n",
    "    Code for making a barplot figure with xlabel, ylabel, legend, title\n",
    "    \n",
    "    '''\n",
    "\n",
    "#### Question 9\n",
    "def main(title, width, height):\n",
    "    #### Function 1\n",
    "    #### Function 2\n",
    "\n",
    "# main('Repartion of patient type attributed to MCTI doctors', 8, 6)"
   ]
  },
  {
   "source": [
    "### II. Accessing, slicing and selecting data\n",
    "\n",
    "- Check this link if you want to all the secrets on <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html'>indexing and selecting data</a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Accessing values from columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #### Collecting all column names in list\n",
    " list(breast_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make a dataframe with the values that you find interesting (for example we could have get this table for the extra questions)\n",
    "breast_dataset[['patient_id','class','doctor_name']]"
   ]
  },
  {
   "source": [
    "### 2. Select specific rows in the table based on their index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Collecting the information for one row\n",
    "breast_dataset.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset[0:10] #### same as breast_dataset.head(n=10)"
   ]
  },
  {
   "source": [
    "### Following the previous example, what is the equivalent of the line `breast_dataset.tail(n=10)`\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer\n",
    "#####"
   ]
  },
  {
   "source": [
    "### 3. Selecting specific rows based on a condition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### With numbers \n",
    "breast_dataset[breast_dataset['mitoses'] == 10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset[breast_dataset['mitoses'] < 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Collect the patients with the smallest and highest cell size uniformity\n",
    "breast_dataset[(breast_dataset['cell_size_uniformity'] == 1) | (breast_dataset['cell_size_uniformity'] == 10 )]"
   ]
  },
  {
   "source": [
    "Alternative line code: <br>\n",
    "`breast_dataset[(breast_dataset['cell_size_uniformity'] == breast_dataset['cell_size_uniformity'].min()) | (breast_dataset['cell_size_uniformity'] == breast_dataset['cell_size_uniformity'].max() )]`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For a string value\n",
    "breast_dataset[breast_dataset['class'] == 'benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For a list of keywords\n",
    "breast_dataset[breast_dataset['doctor_name'].isin(['Dr. Smith', 'Dr. Lee'])]"
   ]
  },
  {
   "source": [
    "\n",
    "### III. Dealing with missing values\n",
    "\n",
    "### 1. How many missing values per column do we have?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NB: In numpy, missing values can be defined with np.nan\n",
    "breast_dataset.isna().sum() "
   ]
  },
  {
   "source": [
    "### Determinant choice: What can we do with these missing values?\n",
    "- [ ] Replace them with zero! - 1\n",
    "- [ ] Remove them all! - 2\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you choose, solution 1, run this cell\n",
    "breast_dataset_with_zero = breast_dataset.fillna(0)\n",
    "\n",
    "breast_dataset_with_zero.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you choose, solution 2, run this cell\n",
    "breast_dataset_with_nona = breast_dataset.dropna()  #drop rows with any column having np.nan values\n",
    "\n",
    "breast_dataset_with_nona.isna().sum()"
   ]
  },
  {
   "source": [
    "### 2. What is the difference of these two methods?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with zero:', breast_dataset_with_zero.shape)\n",
    "print('Dataset with no NA:', breast_dataset_with_nona.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Let's take the dataframe with no na values\n",
    "breast_dataset_with_nona "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reindexing your table after removing few lines - step 1\n",
    "breast_dataset_with_nona = breast_dataset_with_nona.reset_index()\n",
    "breast_dataset_with_nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reindexing your table after removing few lines - step 2\n",
    "breast_dataset_with_nona = breast_dataset_with_nona.drop(columns='index')\n",
    "breast_dataset_with_nona"
   ]
  },
  {
   "source": [
    "### 3. How many unique patients do we have after removing data?  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset.nunique()"
   ]
  },
  {
   "source": [
    "### Do you have a better solution to deal with missing data?\n",
    "- Let's ask hear Mavie's solution!\n",
    "\n",
    "### Try to implement Mavie'solution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cell for Mavie's solution\n",
    "\n"
   ]
  },
  {
   "source": [
    "### How can we explain that we found 645 patients in the study when we have 690 rows in our table?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### IV. Cleaning the dataframe by removing duplicated data\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Identify all lines with duplicated patient_id"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_patients = breast_dataset.duplicated(subset='patient_id', keep=False) #### keep=False \n",
    "                                                                             #### --> Mark all duplicates as True.\n",
    "repeat_patients"
   ]
  },
  {
   "source": [
    "### 2. Collect all the lines with duplicated patient_id"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset[repeat_patients]"
   ]
  },
  {
   "source": [
    "### 3. Removing duplicated lines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset = breast_dataset.drop_duplicates(subset='patient_id', keep ='first') #### keep='first'\n",
    "                                                           #### Mark duplicates as True except for the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset"
   ]
  },
  {
   "source": [
    "### V. Customizing your dataframe\n",
    "\n",
    "Situation 2:\n",
    "The AEBINUM association want your help, they have collected two tables that list the graduated alumni of the bioinformatics program and need to do some statistics on them. As they are dealing with the organization of different events, they kindly ask you some help. \n",
    "\n",
    "### 1. First mission: Charge the two tables\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table_path = 'https://raw.githubusercontent.com/ladyson1806/AEBINUM/master/collect_grad_alumni/2020/AEBINUM_MASTER_ALUMN_LIST_2020.csv'\n",
    "\n",
    "phd_table_path = 'https://raw.githubusercontent.com/ladyson1806/AEBINUM/master/collect_grad_alumni/2020/AEBINUM_PHD_ALUMN_LIST_2020.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Charge your data\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "source": [
    "### 2. Mission 2: Add a student_type column in each table "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table['grade_etudiant'] = 'master'\n",
    "master_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your turn!\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "source": [
    "### 3. Mission 3: Can you make only one table? (Concatening table)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = phd_table.append(master_table)\n",
    "final_table"
   ]
  },
  {
   "source": [
    "### VI. Your time to play! \n",
    "\n",
    "1. Clean the columns `Manuscrit_soumis` et `Grade_obtenu` by collecting only the year using the `re` package <br> and create two new columns with the results\n",
    "    - More about regular expression in Python: https://docs.python.org/3/howto/regex.html\n",
    "    - Hint: `re.findall()` documentation: https://blog.finxter.com/python-re-findall/\n",
    "2. Display a countplot to show of the number of graduated alumni per manuscript submitting year split by `grade_etudiant`\n",
    "    - Hint: `seaborn.countplot()` documentation: https://seaborn.pydata.org/generated/seaborn.countplot.html \n",
    "3. Optional: Propose ideas to make this table cleaner!\n",
    "4. Optional: Propose interesting analyses to do on this table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 1\n",
    "def get_year(x):\n",
    "    if x == 'à venir':\n",
    "        return np.nan\n",
    "    else:\n",
    "        year = ############\n",
    "        return year\n",
    "\n",
    "final_table['Annee_soumission'] = final_table['Manuscrit_soumis'].apply(get_year)\n",
    "final_table['Annee_diplome'] = final_table['Manuscrit_soumis'].apply(get_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Question 2\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "source": [
    "### Example of `df.merge()` utilization: \n",
    "- Documentation: Merge, join, concatenate and compare: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "\n",
    "##### Description of the code\n",
    "- Create a table where you clean the column 'Etudiant_ Directeur' into two columns 'Etudiant' and 'Directeur'\n",
    "- Merge this table with previous final_table\n",
    "- Plot the number of students per reaearch director"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = final_table[['Etudiant_Directeur', 'Titre_Projet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_people_name(x, role):\n",
    "    people_list = x.split(' / ')\n",
    "    if 'etudiant' in role:\n",
    "        student = people_list[0]\n",
    "        return student\n",
    "    if 'directeur' in role:\n",
    "        directeurs = people_list[1:]\n",
    "        for directeur in directeurs :\n",
    "            if '' == directeur:\n",
    "                directeurs.remove(directeur)\n",
    "            if '/ ' in directeur:\n",
    "                old_format = directeur\n",
    "                new_format = old_format.replace(f'/ ', '')\n",
    "                directeurs.remove(old_format)\n",
    "                directeurs.append(new_format)\n",
    "        return ', '.join(directeurs)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean['Etudiant'] = to_clean['Etudiant_Directeur'].apply(get_people_name, args=('etudiant',))\n",
    "to_clean['Directeur'] = to_clean['Etudiant_Directeur'].apply(get_people_name, args=('directeur',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = to_clean[['Titre_Projet', 'Etudiant', 'Directeur']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_table = final_table.merge(to_merge, on='Titre_Projet')\n",
    "clean_table = clean_table.drop(columns='Etudiant_Directeur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Final clean table sort with directeur in alphabetical order\n",
    "clean_table = clean_table.sort_values('Directeur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directeur_order = pd.DataFrame({'count': clean_table.groupby('Directeur').size()}).reset_index().sort_values('count', ascending=False)\n",
    "directeur_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "sns.countplot(y=clean_table['Directeur'], order=directeur_order['Directeur'], color='grey')\n",
    "plt.show()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}